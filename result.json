{
    "talks": [
        {
            "url": "https://nips.cc/Expo/Conferences/2023/talk%20panel/78250",
            "title": "Reinforcement Learning: Trends, Applications, and Challenges"
        }
    ],
    "expo_work_shops": [
        {
            "url": "https://nips.cc/Expo/Conferences/2023/workshop/78405",
            "title": "Production-ready Reinforcement Learning Active Training"
        }
    ],
    "work_shops": [
        {
            "url": "https://nips.cc/virtual/2023/workshop/66519",
            "title": "Goal-Conditioned Reinforcement Learning"
        }
    ],
    "competitions": [
        {
            "url": "https://nips.cc/virtual/2023/competition/66597",
            "title": "The NeurIPS 2023 Neural MMO Challenge: Multi-Task Reinforcement Learning and Curriculum Generation"
        }
    ],
    "posters": [
        {
            "url": "https://nips.cc/virtual/2023/poster/70701",
            "title": "Hierarchical Adaptive Value Estimation for Multi-modal Visual Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71398",
            "title": "Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72510",
            "title": "Online Nonstochastic Model-Free Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71039",
            "title": "Supervised Pretraining Can Learn In-Context Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70304",
            "title": "Policy Optimization for Continuous Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71294",
            "title": "Offline Reinforcement Learning with Differential Privacy"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73430",
            "title": "SustainGym: Reinforcement Learning Environments for Sustainable Energy Systems"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70463",
            "title": "When Demonstrations meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71308",
            "title": "Model-Free Active Exploration in Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72569",
            "title": "Probabilistic Inference in Reinforcement Learning Done Right"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72637",
            "title": "Provably Efficient Offline Reinforcement Learning in Regular Decision Processes"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70631",
            "title": "Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72476",
            "title": "Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70086",
            "title": "Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71950",
            "title": "ODE-based Recurrent Model-free Reinforcement Learning for POMDPs"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72005",
            "title": "Reinforcement Learning with Fast and Forgetful Memory"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73450",
            "title": "COOM: A Game Benchmark for Continual Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71415",
            "title": "Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71771",
            "title": "Dynamics Generalisation in Reinforcement Learning via Adaptive Context-Aware Policies"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70073",
            "title": "Interpretable Reward Redistribution in Reinforcement Learning: A Causal Approach"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70396",
            "title": "Kernelized Reinforcement Learning with Order Optimal Regret Bounds"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71631",
            "title": "The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71832",
            "title": "Information Design in Multi-Agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72548",
            "title": "DIFFER:Decomposing Individual Reward for Fair Experience Replay in Multi-Agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71595",
            "title": "Optimistic Exploration in Reinforcement Learning Using Symbolic Model Estimates"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71800",
            "title": "Percentile Criterion Optimization in Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71384",
            "title": "Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72040",
            "title": "Train Hard, Fight Easy: Robust Meta Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70386",
            "title": "StateMask: Explaining Deep Reinforcement Learning through State Mask"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72745",
            "title": "When is Agnostic Reinforcement Learning Statistically Tractable?"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71095",
            "title": "The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73033",
            "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72652",
            "title": "DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72997",
            "title": "Adjustable Robust Reinforcement Learning for Online 3D Bin Packing"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73067",
            "title": "Efficient Potential-based Exploration in Reinforcement Learning using Inverse Dynamic Bisimulation Metric"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72850",
            "title": "Structured State Space Models for In-Context Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72866",
            "title": "Effectively Learning Initiation Sets in Hierarchical Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73015",
            "title": "Robust Knowledge Transfer in Tiered Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73055",
            "title": "No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72977",
            "title": "General Munchausen Reinforcement Learning with Tsallis Kullback-Leibler Divergence"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72837",
            "title": "Multi-Modal Inverse Constrained Reinforcement Learning from a Mixture of Demonstrations"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72924",
            "title": "Mutual Information Regularized Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73058",
            "title": "Efficient Diffusion Policies For Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72475",
            "title": "Waypoint Transformer: Reinforcement Learning via Supervised Learning with Intermediate Targets"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72755",
            "title": "Adversarial Model for Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72661",
            "title": "Conservative State Value Estimation for Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72777",
            "title": "Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72660",
            "title": "Pre-training Contextualized World Models with In-the-wild Videos for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72613",
            "title": "Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72536",
            "title": "Two Heads are Better Than One: A Simple Exploration Framework for Efficient Multi-Agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72574",
            "title": "Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72436",
            "title": "Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73035",
            "title": "Instructing Goal-Conditioned Reinforcement Learning Agents with Temporal Logic Objectives"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72963",
            "title": "Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72792",
            "title": "Replicability in Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72845",
            "title": "Importance Weighted Actor-Critic for Optimal Conservative Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72518",
            "title": "Model-Free Reinforcement Learning with the Decision-Estimation Coefficient"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72031",
            "title": "MAG-GNN: Reinforcement Learning Boosted Graph Neural Network"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72153",
            "title": "Ensemble-based Deep Reinforcement Learning for Vehicle Routing Problems under Distribution Shift"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72131",
            "title": "Goal-Conditioned Predictive Coding for Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71915",
            "title": "Sequential Preference Ranking for Efficient Reinforcement Learning from Human Feedback"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72253",
            "title": "Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72001",
            "title": "Prediction and Control in Continual Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71961",
            "title": "Sample Efficient Reinforcement Learning in Mixed Systems through Augmented Samples and Its Applications to Queueing Networks"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73613",
            "title": "CORL: Research-oriented Deep Offline Reinforcement Learning Library"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72059",
            "title": "Latent exploration for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72301",
            "title": "Generative Modelling of Stochastic Actions with Arbitrary Constraints in Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72294",
            "title": "Conditional Mutual Information for Disentangled Representations in Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71822",
            "title": "RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72053",
            "title": "Parameterizing Non-Parametric Meta-Reinforcement Learning Tasks via Subtask Decomposition"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72325",
            "title": "A Long $N$-step Surrogate Stage Reward for Deep Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72159",
            "title": "Video Prediction Models as Rewards for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70929",
            "title": "$\\texttt{TACO}$: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/69999",
            "title": "For SALE: State-Action Representation Learning for Deep Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72289",
            "title": "Sample Complexity of Goal-Conditioned Hierarchical Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72240",
            "title": "RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72245",
            "title": "Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72350",
            "title": "Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71759",
            "title": "Performance Bounds for Policy-Based Average Reward Reinforcement Learning Algorithms"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71851",
            "title": "Reward-agnostic Fine-tuning: Provable Statistical Benefits of Hybrid Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72273",
            "title": "Anytime-Competitive Reinforcement Learning with Policy Prior"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72027",
            "title": "Corruption-Robust Offline Reinforcement Learning with General Function Approximation"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71640",
            "title": "A Partially-Supervised Reinforcement Learning Framework for Visual Active Search"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71123",
            "title": "Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71578",
            "title": "Offline Reinforcement Learning for Mixture-of-Expert Dialogue Management"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71646",
            "title": "Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximation"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71206",
            "title": "Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71231",
            "title": "A Definition of Continual Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71307",
            "title": "Inverse Reinforcement Learning with the Average Reward Criterion"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71558",
            "title": "Context Shift Reduction for Offline Meta-Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71027",
            "title": "Constrained Policy Optimization with Explicit Behavior Density For Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71142",
            "title": "Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71114",
            "title": "PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71091",
            "title": "Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71385",
            "title": "STORM: Efficient Stochastic Transformer based World Models for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71228",
            "title": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71183",
            "title": "Decompose a Task into Generalizable Subtasks in Multi-Agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71024",
            "title": "Safe Exploration in Reinforcement Learning: A Generalized Formulation and Algorithms"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71541",
            "title": "Loss Dynamics of Temporal Difference Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71552",
            "title": "Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71427",
            "title": "Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71440",
            "title": "Efficient Exploration in Continuous-time Model-based Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71612",
            "title": "Distributional Model Equivalence for Risk-Sensitive Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70308",
            "title": "Swarm Reinforcement Learning for Adaptive Mesh Refinement"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70469",
            "title": "Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70869",
            "title": "Prioritizing Samples in Reinforcement Learning with Reducible Loss"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70658",
            "title": "Discovering General Reinforcement Learning Algorithms with Adversarial Environment Design"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70570",
            "title": "H-InDex: Visual Reinforcement Learning with Hand-Informed Representations for Dexterous Manipulation"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70916",
            "title": "Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70281",
            "title": "Doubly Robust Augmented Transfer for Meta-Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70606",
            "title": "Team-PSRO for Learning Approximate TMECor in Large Team Games via Cooperative Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70393",
            "title": "Distributional Pareto-Optimal Multi-Objective Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/71143",
            "title": "Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70351",
            "title": "One Risk to Rule Them All: A Risk-Sensitive Perspective on Model-Based Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70278",
            "title": "VOCE: Variational Optimization with Conservative Estimation for Offline Safe Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70875",
            "title": "Supported Value Regularization for Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70549",
            "title": "Reining Generalization in Offline Reinforcement Learning via Representation Distinction"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70088",
            "title": "Revisiting the Minimalist Approach to Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70577",
            "title": "Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70373",
            "title": "Trust Region-Based Safe Distributional Reinforcement Learning for Multiple Constraints"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70384",
            "title": "SPQR: Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70420",
            "title": "PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70926",
            "title": "Iterative Reachability Estimation for Safe Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70331",
            "title": "Reinforcement Learning with Simple Sequence Priors"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70670",
            "title": "Deep Reinforcement Learning with Plasticity Injection"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70709",
            "title": "Active Vision Reinforcement Learning under Limited Visual Observability"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70828",
            "title": "Creating Multi-Level Skill Hierarchies in Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70655",
            "title": "Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73066",
            "title": "Multi-Agent Meta-Reinforcement Learning: Sharper Convergence Rates with Task Similarity"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70618",
            "title": "BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70515",
            "title": "Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70887",
            "title": "Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70359",
            "title": "Provably Efficient Offline Goal-Conditioned Reinforcement Learning with General Function Approximation and Single-Policy Concentrability"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/72708",
            "title": "Tempo Adaptation in Non-stationary Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70892",
            "title": "Policy Finetuning in Reinforcement Learning via Design of Experiments using Offline Data"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70757",
            "title": "Learning to Influence Human Behavior with Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73483",
            "title": "TradeMaster: A Holistic Quantitative Trading Platform Empowered by Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70104",
            "title": "Suggesting Variable Order for Cylindrical Algebraic Decomposition via Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70114",
            "title": "Reflexion: language agents with verbal reinforcement learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73567",
            "title": "Safety Gymnasium: A Unified Safe Reinforcement Learning Benchmark"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73497",
            "title": "MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70037",
            "title": "Natural Actor-Critic for Robust Reinforcement Learning with Function Approximation"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73882",
            "title": "Semantic HELM: A Human-Readable Memory for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73602",
            "title": "Minigrid & Miniworld: Modular & Customizable Reinforcement Learning Environments for Goal-Oriented Tasks"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73492",
            "title": "Hokoff: Real Game Dataset from Honor of Kings and its Offline Reinforcement Learning Benchmarks"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70254",
            "title": "Survival Instinct in Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/69911",
            "title": "Decision Stacks: Flexible Reinforcement Learning via Modular Generative Models"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73576",
            "title": "Pgx: Hardware-Accelerated Parallel Game Simulators for Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73489",
            "title": "A Toolkit for Reliable Benchmarking and Research in Multi-Objective Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70269",
            "title": "Understanding and Addressing the Pitfalls of Bisimulation-based Representations in Offline Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70151",
            "title": "Self-Supervised Reinforcement Learning that Transfers using Random Features"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70249",
            "title": "Belief Projection-Based Reinforcement Learning for Environments with Delayed Feedback"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73592",
            "title": "RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70060",
            "title": "Small batch deep reinforcement learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70117",
            "title": "Pitfall of Optimism: Distributional Reinforcement Learning by Randomizing Risk Criterion"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70196",
            "title": "CQM: Curriculum Reinforcement Learning with a Quantized World Model"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73577",
            "title": "Gigastep - One Billion Steps per Second Multi-agent Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73723",
            "title": "OFCOURSE: A Multi-Agent Reinforcement Learning Environment for Order Fulfillment"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70222",
            "title": "Replicable Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/70257",
            "title": "On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling and Beyond"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/69969",
            "title": "On the Importance of Exploration for Generalization in Reinforcement Learning"
        },
        {
            "url": "https://nips.cc/virtual/2023/poster/73695",
            "title": "SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning"
        }
    ]
}